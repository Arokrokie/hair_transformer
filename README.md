## Hair Transformer — Project Overview

Hair Transformer is a Django-based web app that lets users upload a photo and see hair-style transformations generated by AI. The app includes image analysis, hair segmentation, and generated hairstyle previews saved as result images. It was built as a student project and includes demo samples and a lightweight UI for uploading and viewing results.

Features

- Upload a photo and start a head-hair transformation job.
- Background processing with polling for progress updates.
- Face / hair analysis and segmentation (used to generate realistic previews).
- Stores generated transformation images in `media/results/` and user uploads in `media/uploads/`.

Repository layout (important files)

- `manage.py` — Django CLI entrypoint.
- `hair_project/` — Django project settings and WSGI/ASGI entry.
- `hair_transformation/` — Django app implementing upload, processing, and results views.
  - `templates/` — HTML templates used by the app.
  - `static/` — static assets for the UI (images, SVGs).
  - `utils/hair_ai.py` — image-processing / model integration helpers used by background tasks.
- `media/` — runtime storage for uploaded images and generated results (not recommended to commit large files here).
- `requirements.txt` — Python dependencies (trimmed for CPU deployment; see notes below).

Quick local setup (recommended)

1. Create and activate a virtual environment:

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1   # PowerShell
# or on cmd: .\.venv\Scripts\activate
# or on Unix: source .venv/bin/activate
```

2. Upgrade pip and install dependencies:

```powershell
pip install -U pip
pip install -r requirements.txt
```

3. Apply migrations and run the development server:

```powershell
python manage.py migrate
python manage.py runserver
```

4. Open `http://127.0.0.1:8000/` and use the web UI to upload a sample image.

Environment variables

- `DJANGO_SECRET_KEY` (optional) — if not set, a default development key is used (do not use in production).
- `DATABASE_URL` / DB settings — the project uses SQLite by default (`db.sqlite3`). For production, configure a proper DB and update `hair_project/settings.py` accordingly.
- `SEGFORMER_MODEL_PATH` (optional) — set this if you move the bundled SegFormer directory; defaults to `<project_root>/segformer_b2_clothes`.

Notes about models, large dependencies, and deployment

- The runtime now only needs PyTorch/torchvision (for the SegFormer model) plus Hugging Face `transformers`. Install CPU wheels manually so pip does not attempt CUDA builds.
- A copy of the SegFormer weights lives in `segformer_b2_clothes/`. The loader attempts that folder first (or the path in `SEGFORMER_MODEL_PATH`) before falling back to Hugging Face, eliminating cold-start downloads on Render.
- No local Stable Diffusion or diffusers pipelines run anymore; hairstyle generation flows exclusively through the Replicate API, so there are no extra ML downloads beyond SegFormer.
- Do NOT commit your `venv/` or any large model caches to the repository. Use Git LFS or external object storage if you need to persist downloaded weights.

Deploying to Render (CPU instance)

1. In Render's Service settings, set the **Build Command** to:

```bash
pip install -U pip
# install CPU PyTorch (adjust versions as needed)
pip install "torch==2.9.0+cpu" "torchvision==0.24.0+cpu" -f https://download.pytorch.org/whl/torch_stable.html
pip install -r requirements.txt
```

2. Set the **Start Command** on Render to:

```bash
gunicorn hair_project.wsgi --bind 0.0.0.0:$PORT
```

3. Configure environment variables (`DJANGO_SECRET_KEY`, database settings, and any API keys) in Render's dashboard.

If you need GPU acceleration

- Render's standard instances are CPU-only. For GPU workloads you must deploy to a provider that offers GPU instances (AWS/GCP/Azure, Paperspace, Gradient, or a Render GPU plan if available). If you restore optional GPU-only packages (diffusers, bitsandbytes, etc.), manage them via a separate `requirements.gpu.txt`.

Recommended additional files

- `requirements.cpu.txt` — mirrors `requirements.txt`; keep it if you want a clearly named CPU-only lockfile.
- `requirements.gpu.txt` — only necessary if you reintroduce GPU-specific libraries.

Troubleshooting

- If pip fails during deployment with dependency conflicts: pre-install the CPU PyTorch wheel (see Build Command) before running `pip install -r requirements.txt`.
- If you see very large wheel uploads or git rejects, remove `venv/` from the repo and add it to `.gitignore`.

Contributing

- Run tests (if any) and follow the project style. Open issues or PRs with clear descriptions.

License & Credits

- This is a student project. Replace with license information if you plan to publish.

If you want, I can:

- Create `requirements.cpu.txt` and `requirements.gpu.txt` now.
- Add a `Procfile` for Render or a more detailed deployment script.
- Add a short troubleshooting section with common Render build log patterns and fixes.
